{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ3hO8YZajAG"
      },
      "outputs": [],
      "source": [
        "###\n",
        "# Importar librerias necesarias para el procesamiento del dataframe\n",
        "###\n",
        "\n",
        "'''Pandas para la lectura del archivo'''\n",
        "import pandas as pd\n",
        "\n",
        "'''Sns y plt para organizar los graficos visuales'''\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###\n",
        "# Importar librerias necesarias del modelo, el entrenamiendo y las métricas\n",
        "###\n",
        "\n",
        "'''Train test split para dividir el data frame en partes'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "'''Preprocesamiento de datos'''\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "'''Transformadores de columnas para procesar datos'''\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "'''Modelo de ejecución de entrenamiento'''\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "'''Metricas de desempeño'''\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
        "\n",
        "'''Pipelines para transformar los datos procesados y el modelo'''\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#\n",
        "# Importar el archivo csv del set online llamado car heart_cleveland_upload.csv\n",
        "#\n",
        "df = pd.read_csv('/content/sample_data/heart_cleveland_upload.csv')\n",
        "\n",
        "#\n",
        "# 1. Para este caso de estudio todas las variables tienen relación y se\n",
        "# trabajaran con todas en el procesamiento y entremaniento del modelo\n",
        "#\n",
        "\n",
        "#\n",
        "# 2. Preprocesamiento y Selección de Características\n",
        "#\n",
        "features = df.drop('condition', axis=1)\n",
        "target = df['condition']\n",
        "\n",
        "#\n",
        "# Preprocesamiento para variables numéricas y categóricas\n",
        "#\n",
        "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "\n",
        "#\n",
        "# 3. Selección de caracteristicas relevantes\n",
        "#\n",
        "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(drop='first')\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "#\n",
        "# 4. Dividir el conjunto de datos\n",
        "#\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "#\n",
        "# Creación del pipeline de regresión logística\n",
        "#\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "#\n",
        "# 5. Entrenamiento del modelo\n",
        "#\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "#\n",
        "# 6. Evaluación del desempeño del modelo\n",
        "#\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#\n",
        "# Predecir probabilidades para el conjunto de test\n",
        "#\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "print(f\"Auc Score: {auc}\")\n",
        "\n",
        "#\n",
        "# Imprimir el reporte de clasificación\n",
        "#\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "#\n",
        "# 7. Generar y mostrar la matriz de confusión y grafica adicional ROC\n",
        "#\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "#\n",
        "# Calcular la curva ROC\n",
        "#\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "\n",
        "#\n",
        "# Graficar la curva ROC\n",
        "#\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Dashed diagonal\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    }
  ]
}